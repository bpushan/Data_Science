{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd12760-c7fb-4f27-85e0-9c805a1e1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374034b-e34d-4c5c-89d5-66fba84f442a",
   "metadata": {},
   "source": [
    "#### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64dc3880-1ed3-4917-ba8d-c57b9d76bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (5572, 2)\n"
     ]
    }
   ],
   "source": [
    "text_message = pd.read_csv('SPAM_text_message.csv')\n",
    "print('Shape: ',text_message.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1035bce7-93d4-4ce0-aec8-a69f145d45bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_message.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d69c03-96b6-4646-94e5-dbf20a30b7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_message['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f18819-eea3-4855-982d-b504d67f1f70",
   "metadata": {},
   "source": [
    "#### Breaking the Input data into Text and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af5bc46-6967-40b5-a624-5e89364d4e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of texts : 5572\n",
      "number of labels:  5572\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "for i, label in enumerate(text_message['Category']):\n",
    "    texts.append(text_message['Message'][i])\n",
    "    if label == 'ham':\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "\n",
    "texts = np.asarray(texts)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "print(\"number of texts :\" , len(texts))\n",
    "print(\"number of labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a0e308-8e87-41b9-aab4-34a06c6f4d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n",
      "------\n",
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
      " 'Ok lar... Joking wif u oni...'\n",
      " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\n",
      " 'U dun say so early hor... U c already then say...'\n",
      " \"Nah I don't think he goes to usf, he lives around here though\"]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0:5])\n",
    "print('------')\n",
    "print(texts[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0ed63c3-f5cd-4182-8475-afe6c46c035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "3.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tensorflow.__version__)\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc2ec2-fc08-4c38-990e-a930f87f24a6",
   "metadata": {},
   "source": [
    "#### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce576d8d-980b-4c03-ad0f-12178cc8c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, Embedding, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb141d0d-d7cf-4cc2-9948-4adc2412d44b",
   "metadata": {},
   "source": [
    "##### Converting into sequence of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d09ec95f-e1fa-40fa-bd3e-c0998a8e9cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9004 unique words: \n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Found {0} unique words: \".format(len(word_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a64f398-6788-42b1-ac90-1b389311547b",
   "metadata": {},
   "source": [
    "##### Padding the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "825fec92-20df-4cec-b5bf-fdd7a3bcbb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (5572, 500)\n"
     ]
    }
   ],
   "source": [
    "# number of words used as features\n",
    "max_features = 10000\n",
    "# cut off the words after seeing 500 words in each document(email)\n",
    "maxlen = 500\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "print(\"data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d8400-d3cb-4c20-a950-e62691db509d",
   "metadata": {},
   "source": [
    "#### Creating the Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "463bbaa9-88a3-44fc-a351-49643c2abdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# shuffle data\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdf86931-f367-44e3-b743-6aab7fd2a4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Training: 4457,   Validation 1115 \n"
     ]
    }
   ],
   "source": [
    "# we will use 80% of data as training, 20% as validation data\n",
    "training_samples = int(text_message.shape[0] * .8)\n",
    "validation_samples = int(text_message.shape[0] - training_samples)\n",
    "# sanity check\n",
    "print(len(texts) == (training_samples + validation_samples))\n",
    "print(\"Training: {0},   Validation {1} \".format(training_samples, validation_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fa61981-d629-4259-9a86-e2ab59b1ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "texts_test = data[training_samples:]\n",
    "y_test = labels[training_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf918b-bc7c-4117-81f0-3eddd509411a",
   "metadata": {},
   "source": [
    "#### Building a SimpleRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8ce5edd-88c0-4bba-b15c-c095cfb30989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 140ms/step - acc: 0.8398 - loss: 0.4001 - val_acc: 0.9619 - val_loss: 0.1336\n",
      "Epoch 2/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - acc: 0.9802 - loss: 0.0937 - val_acc: 0.9832 - val_loss: 0.0592\n",
      "Epoch 3/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 124ms/step - acc: 0.9870 - loss: 0.0523 - val_acc: 0.9832 - val_loss: 0.0579\n",
      "Epoch 4/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - acc: 0.9927 - loss: 0.0293 - val_acc: 0.9888 - val_loss: 0.0402\n",
      "Epoch 5/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - acc: 0.9942 - loss: 0.0224 - val_acc: 0.9821 - val_loss: 0.0612\n",
      "Epoch 6/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step - acc: 0.9948 - loss: 0.0224 - val_acc: 0.9854 - val_loss: 0.0531\n",
      "Epoch 7/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - acc: 0.9714 - loss: 0.0874 - val_acc: 0.9652 - val_loss: 0.1048\n",
      "Epoch 8/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step - acc: 0.9932 - loss: 0.0240 - val_acc: 0.9641 - val_loss: 0.0921\n",
      "Epoch 9/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - acc: 0.9955 - loss: 0.0189 - val_acc: 0.9305 - val_loss: 0.1951\n",
      "Epoch 10/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 125ms/step - acc: 0.9843 - loss: 0.0459 - val_acc: 0.9809 - val_loss: 0.0634\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model_rnn = model.fit(texts_train, y_train, epochs=10, batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf4538-2b8d-43b3-a32b-bfd1a91cabaa",
   "metadata": {},
   "source": [
    "#### Testing the model with the Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5eac840-bd28-45e3-a8a2-b371f630a6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - acc: 0.9824 - loss: 0.0601\n",
      "Test loss is 0.07 accuracy is 0.98  \n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(texts_test)\n",
    "acc = model.evaluate(texts_test, y_test)\n",
    "print(\"Test loss is {0:.2f} accuracy is {1:.2f}  \".format(acc[0],acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d1d9d-6fe4-4738-9b0d-957f95d19503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
